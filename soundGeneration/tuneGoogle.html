<body>
  <script src="js/dsp.js"></script>
  <script src="js/pitchShift.js"></script>
<script>
var soundSource
var soundBuffer
// var url = 'http://thingsinjars.com/lab/web-audio-tutorial/hello.mp3'
var url = 'http://translate.google.com/translate_tts?tl=da&q=Og%20se%20hende%20brande'

var audioCtx = new (window.AudioContext || window.webkitAudioContext)();


var fftFrameSize = 2048;
var nSamples = 2048;
var shiftValue = 1.4
var shifter = new Pitchshift(fftFrameSize, audioCtx.sampleRate, 'FFT');

var scriptNode = audioCtx.createScriptProcessor(nSamples, 1, 1);

// Give the node a function to process audio events
scriptNode.onaudioprocess = function(audioProcessingEvent) {
  var inputBuffer = audioProcessingEvent.inputBuffer;
  var outputBuffer = audioProcessingEvent.outputBuffer;

  // Loop through the output channels (in this case there is only one)
  for (var channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
    var inputData = inputBuffer.getChannelData(channel);
    var outputData = outputBuffer.getChannelData(channel);

    shifter.process(shiftValue, inputData.length, 4, inputData);
    var out_data = outputData;
    for (i = 0; i < out_data.length; ++i) {
        out_data[i] = shifter.outdata[i];
        // outputData[i] = inputData[i]
    }
  }
}

// create web audio api context

function startSound() {
        // Note: this loads asynchronously
        var request = new XMLHttpRequest();
        request.open("GET", url, true);
        request.responseType = "arraybuffer";

        // Our asynchronous callback
        request.onload = function() {
            var audioData = request.response;
            audioGraph(audioData);
        };
        request.send();
    }

// This is the code we are interested in
function audioGraph(audioData) {
    // create a sound source
    soundSource = audioCtx.createBufferSource();
    // The Audio Context handles creating source buffers from raw binary
    audioCtx.decodeAudioData(audioData, function(soundBuffer){
        // Add the buffered data to our object
        soundSource.buffer = soundBuffer;
        // Plug the cable from one thing to the other

        soundSource.connect(scriptNode);
        scriptNode.connect(audioCtx.destination);

        // Finally
        playSound(soundSource);
    });
}

function playSound() {
    // play the source now
    soundSource.start(audioCtx.currentTime);
}

startSound()

function makeDistortionCurve(amount) {
  var k = typeof amount === 'number' ? amount : 50,
    n_samples = 44100,
    curve = new Float32Array(n_samples),
    deg = Math.PI / 180,
    i = 0,
    x;
  for ( ; i < n_samples; ++i ) {
    x = i * 2 / n_samples - 1;
    curve[i] = ( 3 + k ) * x * 20 * deg / ( Math.PI + k * Math.abs(x) );
  }
  return curve;
};



// // create Oscillator node
// var oscillator = audioCtx.createOscillator();
// oscillator.type = 'sine';
// oscillator.frequency.value = 204.8; // value in hertz
// oscillator.connect(audioCtx.destination)
// oscillator.start();

</script>
</body>
